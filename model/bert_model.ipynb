{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import h5py\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTING_ONLY = False\n",
    "dataroot = '/hpcwork/lect0099/data'\n",
    "imgid_dataroot = dataroot+\"/imgids\"\n",
    "adaptive = False\n",
    "\n",
    "h5_dataroot = dataroot+\"/Bottom-up-features-adaptive\"\\\n",
    "if adaptive else dataroot+\"/Bottom-up-features-fixed\"\n",
    "imgid_dataroot = dataroot+\"/imgids\"\n",
    "name = 'train'\n",
    "prefix = '36'\n",
    "\n",
    "label2ans_path = os.path.join(dataroot, 'cache',\n",
    "                                'trainval_label2ans.pkl')\n",
    "label2ans = pickle.load(open(label2ans_path, 'rb'))\n",
    "\n",
    "img_id2idx = pickle.load(\n",
    "    open(os.path.join(imgid_dataroot, '%s%s_imgid2idx.pkl' %\n",
    "                        (name, '' if adaptive else prefix)), 'rb'))\n",
    "\n",
    "h5_path = os.path.join(h5_dataroot, '%s%s.hdf5' %\n",
    "                        (name, '' if adaptive else prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretable Counting for Visual Question Answering\n",
    "def is_howmany(q, a, label2ans):\n",
    "    if 'how many' in q.lower() or \\\n",
    "       ('number of' in q.lower() and 'number of the' not in q.lower()) or \\\n",
    "       'amount of' in q.lower() or \\\n",
    "       'count of' in q.lower():\n",
    "        if a is None or answer_filter(a, label2ans):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_filter(answers, label2ans, max_num=10):\n",
    "    for ans in answers['labels']:\n",
    "        if label2ans[ans].isdigit() and max_num >= int(label2ans[ans]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _create_entry(img, question, answer):\n",
    "    if answer is not None:\n",
    "        answer.pop('image_id')\n",
    "        answer.pop('question_id')\n",
    "    entry = {\n",
    "        'question_id': question['question_id'],\n",
    "        'image_id': question['image_id'],\n",
    "        'image': img,\n",
    "        'question': question['question'],\n",
    "        'answer': answer}\n",
    "    return entry\n",
    "\n",
    "def assert_eq(real, expected):\n",
    "    assert real == expected, '%s (true) vs %s (expected)' % (real, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_dataset(dataroot, name, img_id2val, label2ans):\n",
    "    \"\"\"Load entries\n",
    "\n",
    "    img_id2val: dict {img_id -> val} val can be used to\n",
    "                retrieve image or features\n",
    "    dataroot: root path of dataset\n",
    "    name: 'train', 'val', 'test-dev2015', test2015'\n",
    "    \"\"\"\n",
    "    question_path = os.path.join(\n",
    "        dataroot, 'Questions/v2_OpenEnded_mscoco_%s_questions.json' %\n",
    "        (name + '2014' if 'test' != name[:4] else name))\n",
    "    questions = sorted(json.load(open(question_path))['questions'],\n",
    "                       key=lambda x: x['question_id'])\n",
    "    # train, val\n",
    "    if 'test' != name[:4]:\n",
    "        answer_path = os.path.join(dataroot, 'cache', '%s_target.pkl' % name)\n",
    "        answers = pickle.load(open(answer_path, 'rb'))\n",
    "        answers = sorted(answers, key=lambda x: x['question_id'])\n",
    "\n",
    "        assert_eq(len(questions), len(answers))\n",
    "        entries = []\n",
    "        for question, answer in zip(questions, answers):\n",
    "            assert_eq(question['question_id'], answer['question_id'])\n",
    "            assert_eq(question['image_id'], answer['image_id'])\n",
    "            img_id = question['image_id']\n",
    "            if not COUNTING_ONLY \\\n",
    "               or is_howmany(question['question'], answer, label2ans):\n",
    "                entries.append(_create_entry(img_id2val[img_id],\n",
    "                                             question, answer))\n",
    "    # test2015\n",
    "    else:\n",
    "        entries = []\n",
    "        for question in questions:\n",
    "            img_id = question['image_id']\n",
    "            if not COUNTING_ONLY \\\n",
    "               or is_howmany(question['question'], None, None):\n",
    "                entries.append(_create_entry(img_id2val[img_id],\n",
    "                                             question, None))\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.07122540473938\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "entries_test = _load_dataset(dataroot, name, img_id2idx, label2ans)\n",
    "entries_df = pd.DataFrame(entries_test)\n",
    "questions = entries_df.question.values\n",
    "total_time = time.time() - start\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      " Original:  How many cookies can be seen?\n",
      "Tokenized:  ['how', 'many', 'cookies', 'can', 'be', 'seen', '?']\n",
      "Token IDs:  [2129, 2116, 16324, 2064, 2022, 2464, 1029]\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Print the original question.\n",
    "print(' Original: ', questions[0])\n",
    "# Print the question split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(questions[0]))\n",
    "# Print the question mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(questions[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for encoding:  117.5828161239624\n"
     ]
    }
   ],
   "source": [
    "start_time_2 = time.time()\n",
    "# Tokenize all of the questions and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every question...\n",
    "for ques in questions:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the question.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the question to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        ques,                      # question to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 32,           # Pad & truncate all questions.\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded question to the list.    \n",
    "    input_ids.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "# # Add the encoded question to the list.    \n",
    "# input_ids.append(encoded_dict['input_ids'])\n",
    "# print(type(input_ids))\n",
    "# print(type(encoded_dict))\n",
    "\n",
    "# And its attention mask (simply differentiates padding from non-padding).\n",
    "attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "# input_ques_ids = torch.cat(input_ids, dim=0)\n",
    "# attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(labels)\n",
    "\n",
    "# Print question 0, now as a list of IDs.\n",
    "# print('Original: ', questions[0])\n",
    "# print('Token IDs:', input_ques_ids[0])\n",
    "# print('Attention masks: ', attention_masks[0])\n",
    "\n",
    "print(\"time for encoding: \", time.time() - start_time_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertModel.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.  \n",
    "    output_attentions = True, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "bert_model = model.to(device)\n",
    "bert_logits = []\n",
    "for input in input_ids:\n",
    "    output = model(**input)\n",
    "    bert_logits.append(output)\n",
    "\n",
    "print(bert_logits[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regat_common",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
